#! /usr/bin/env python3
"""
Manage configuration files and tools. Organize them into groups.
"""
import os
import sys
import argparse
import subprocess
import difflib
import shutil
import itertools
import yaml
from pathlib import Path
from datetime import datetime


class ConfitError(Exception):
    pass


class ConfGroup:
    def __init__(self,
                 name: str,
                 dest: Path,
                 install_files: list[tuple[str, str]],
                 sync_files: list[tuple[str, str]] | None = None,
                 post_install_cmds: list[tuple[str, str]] = list(),
                 check_binaries: list[tuple[str, str]] = list(),
                 max_backups: int = 5) -> None:
        """
        - 'name': the name of this configuration group
        - 'dest': the destination path (all other paths are considered
                  to be relative to the destination path)
        - 'install_files': a list of file/directory pairs that should be installed by 'install()`
        - 'sync_files': a list of file/directory pairs that should be synchronized by 'synchronize()'
                        (identical to 'install_files' if empty)
        - 'post_install_cmds': list of tuples, each containing a command and the working directory
                               where to execute it (relative to the destination path)
        - 'check_binaries': list of tuples, each containing the name of a binary that should be in
                            $PATH and some description (e.g. where to get it).
        - 'max_backups': max. nr. of backups to keep
        """
        self.name = name
        self.dest = dest
        self.install_files = install_files
        # if 'sync_files' is None, we synchronize everything that is installed
        # -> if it's empty, we synchronize NOTHING
        self.sync_files = sync_files if sync_files is not None else install_files
        self.post_install_cmds = post_install_cmds
        self.check_binaries = check_binaries
        self.max_backups = max_backups

    def backup(self, files: str = 'install') -> None:
        """
        Back up existing files by renaming them. Renaming is done by appending a suffix
        consisting of '.ba' + timestamp (corresponding to the last modification time).
        Retains a maximum of 'max_backup' backup files (the oldest is deleted).
        """
        printq(f"=> Backing up '{self.name}'")
        if files == 'install':
            backup_files = self.install_files
        elif files == 'sync':
            backup_files = self.sync_files
        else:
            raise ConfitError(f"Got invalid files '{files}' to back up")
        for src, dst in backup_files:
            dst_path = self.dest / dst
            if dst_path.exists():
                timestamp = datetime.fromtimestamp(dst_path.stat().st_mtime).strftime('%Y-%m-%d-%H:%M:%S')
                backup_path = dst_path.parent / f"{dst_path.name}.ba.{timestamp}"
                if backup_path.exists():
                    counter = 1
                    while backup_path.exists():
                        backup_path = Path(f'{backup_path}.{counter}')
                        counter += 1
                printq(f" > renaming '{dst_path}' to '{backup_path}'")
                dst_path.rename(backup_path)

                # respect the max. nr. of backups
                backups = sorted(dst_path.parent.glob(f"{dst_path.name}.ba.*"),
                                 key=lambda p: p.stat().st_mtime)
                if len(backups) > self.max_backups:
                    for old_backup in backups[:-self.max_backups]:
                        printq(f" > removing old backup '{old_backup}'")
                        old_backup.unlink()
        printq(" > DONE")

    def install(self, force: bool = False) -> None:
        """
        Copy all 'install_files' of the current group to their destination. Expect the target
        to NOT exist (because it's renamed during backup). If it exists, raise an exception.
        If 'force' is true, overwrite the destination.
        """

        printq(f"=> Installing '{self.name}'")
        for src, dst in self.install_files:
            dst_path = self.dest / dst
            if dst_path.exists() and not force:
                raise ConfitError(f"Destination '{dst_path}' exists (has it been backed up?)! Aborting installation.")
            self._do_copy(Path(src), dst_path)
        printq(" > DONE")

    def post_install(self) -> None:
        """
        If this groups has a 'post_install_cmds' list, each command is executed in the
        according working directory.
        """
        printq(f"=> Running post-install commands for '{self.name}'")
        if len(self.post_install_cmds) == 0:
            printq(" > Nothing to do.")
        else:
            for cmd, wdir in self.post_install_cmds:
                full_wdir = self.dest / wdir
                printq(f" > executing '{cmd}' in '{full_wdir}'")
                subprocess.run(cmd, shell=True, cwd=full_wdir, check=True)
            printq(" > DONE")

    def apply(self, force: bool = False) -> None:
        """
        Copy all 'sync_files' of the current group to their destination. Expect the target
        to NOT exist (because it's renamed during backup). If it exists, raise an exception.
        If 'force' is true, overwrite the destination.
        """

        printq(f"=> Applying '{self.name}'")
        if len(self.sync_files) == 0:
            printq(" > Nothing to do.")
        else:
            for src, dst in self.sync_files:
                dst_path = self.dest / dst
                if dst_path.exists() and not force:
                    raise ConfitError(f"Destination '{dst_path}' exists (has it been backed up?)! Aborting apply.")
                self._do_copy(Path(src), dst_path)
            printq(" > DONE")

    def synchronize(self) -> None:
        """
        Copy the 'sync_files' of the current group from their destination to the confit repo.
        Note that files missing in the destination are NOT deleted in the repository!
        """
        printq(f"=> Synchronizing '{self.name}'")
        if len(self.sync_files) == 0:
            printq(" > Nothing to do.")
        else:
            for src, dst in self.sync_files:
                src_path = Path(src)
                dst_path = self.dest / dst
                if dst_path.exists():
                    self._do_copy(dst_path, src_path)
                printq(f" -> '{dst_path}' does not exist, skipping synchronization")
            printq(" > DONE")

    def diff(self) -> bool:
        """
        Compare the installed files of the current group vs the files in this repo.
        If it's a file, make a unified diff and print it if there's an actual difference.
        If it's a directory, check if any of the files differ or if any file exists in one but not in the other directory.
        This is done recursively. In case of differing files, print a unified diff.
        Return 'True' if differences are found, 'False' otherwise.
        """
        printq(f"=> Diff'ing '{self.name}'")
        diff_found = False
        if len(self.sync_files) == 0:
            printq(" > Nothing to do.")
        else:
            for src, dst in self.sync_files:
                dst_path = self.dest / dst
                src_path = Path(src)
                # diff
                if not dst_path.exists():
                    printq(f" > '{dst_path}' does not exist")
                    diff_found = True
                elif not src_path.exists():
                    printq(f" > '{src_path}' does not exist in this repo")
                    diff_found = True
                elif dst_path.is_dir():
                    if self._diff_directories(src_path, dst_path):
                        diff_found = True
                elif dst_path.is_file():
                    if self._diff_files(src_path, dst_path):
                        diff_found = True
            printq(" > DONE ({} differences found)".format('' if diff_found else 'no'))
        return diff_found

    def check(self) -> bool:
        """
        Check if the binaries in 'check_binaries' are available in $PATH.
        Return 'True' if all binaries have been found, 'False' otherwise.
        """
        printq(f"=> Checking available binaries for '{self.name}'")
        all_found = True
        for binary, description in self.check_binaries:
            binary_path = shutil.which(binary)
            printq(f" > {binary} ({description}) ... ", end='', flush=True)
            if binary_path:
                printq("found")
            else:
                printq("NOT found")
                all_found = False
        printq(" > DONE")
        return all_found

    def _do_copy(self, src: Path, dst: Path) -> None:
        if rsync:
            printq(f" > '{src}' -> '{dst}' (rsync)")
            if src.is_dir():
                # add trailing slashes to directories to ensure correct behaviour
                # NOTE: pathlib always strips trailing `/`
                subprocess.run([rsync, '-a', f'{src}/', f'{dst}/'], check=True)
            else:
                subprocess.run([rsync, '-a', src, dst], check=True)
        else:
            printq(f" > '{src}' -> '{dst}' (cp)")
            if dst.exists() and dst.is_dir():
                # if destination exists and is a directory, overwrite it
                # NOTE: with 'cp', we want the source without trailing `/`, in order to
                # correctly handle symlinks (but it's recommended to add it to the destination)
                subprocess.run(["cp", "-a", str(src), f'{dst.parent}/'], check=True)
            else:
                subprocess.run(['cp', '-a', str(src), str(dst)], check=True)

    def _diff_files(self, src_file: Path, dst_file: Path) -> bool:
        printq(f" > '{src_file}' vs. '{dst_file}'")
        if src_file.exists() and not dst_file.exists():
            printq(f" > '{src_file}' exists in this repo but not in the destination")
            return True
        if dst_file.exists() and not src_file.exists():
            printq(f" > '{dst_file}' exists in the destination but not in this repo")
            return True
        diff_found = False
        with open(src_file, 'r') as src_f, open(dst_file, 'r') as dst_f:
            try:
                src_lines = src_f.readlines()
                dst_lines = dst_f.readlines()
                diff = difflib.unified_diff(src_lines, dst_lines, fromfile=str(src_file), tofile=str(dst_file))
                diff_output = ''.join(diff)
                if diff_output:
                    diff_found = True
                    if delta:
                        process = subprocess.Popen([delta, '--line-numbers'],
                                                   stdin=subprocess.PIPE,
                                                   stdout=subprocess.PIPE,
                                                   stderr=subprocess.PIPE)
                        stdout, stderr = process.communicate(input=diff_output.encode())
                        if process.returncode == 0:
                            printq(stdout.decode())
                        else:
                            printe(f"'delta' failed with error: {stderr.decode()}")
                    else:
                        printq(diff_output)
            except Exception as e:
                printe(f"Failed to diff '{src_file}' and '{dst_file}': {e}")
        return diff_found

    def _diff_directories(self, src_dir: Path, dst_dir: Path,
                          diff_found: bool = False) -> bool:
        """
        Recursively compare directories and print diffs for differing files.
        """
        printq(f" > '{src_dir}' vs. '{dst_dir}'")
        # compare directories
        for src_file in src_dir.iterdir():
            dst_file = dst_dir / src_file.name
            # diff
            if src_file.is_dir():
                if dst_file.exists() and dst_file.is_dir():
                    # make recursive call with the current 'diff_found' to keep the state
                    diff_found = self._diff_directories(src_file, dst_file, diff_found)
                elif dst_file.is_file():
                    printq(f" > '{src_file}' is a directory while '{dst_file}' is a file.")
                    diff_found = True
                else:
                    diff_found = True
                    printq(f" > Directory '{src_file}' exists in this repo but not in the destination.")
            elif src_file.is_file():
                if dst_file.exists() and dst_file.is_file():
                    # never set 'diff_found' to False, it may already be True
                    if self._diff_files(src_file, dst_file):
                        diff_found = True
                elif dst_file.is_dir():
                    printq(f" > '{src_file}' is a file while '{dst_file}' is a directory.")
                    diff_found = True
                else:
                    printq(f" > File '{src_file}' exists in this repo but not in the destination.")
                    diff_found = True
        for dst_file in dst_dir.iterdir():
            src_file = src_dir / dst_file.name
            if not src_file.exists():
                printq(f" > File '{dst_file}' exists in the destination but not in this repo.")
                diff_found = True
        return diff_found


# global variables
confit_files = ['.conf.it', 'conf.it', 'confit.yaml', '.confit.yaml']
config: dict
groups: dict[str, ConfGroup]
delta: str | None
rsync: str | None
quiet: bool = False


def printe(*args, **kwargs):
    " Print to stderr. "
    print(*args, file=sys.stderr, **kwargs)


def printq(*args, **kwargs):
    " Print if not quiet. "
    global quiet
    if not quiet:
        print(*args, **kwargs)


def find_delta() -> str | None:
    """
    Check if the 'delta' binary is available in the environment and return its full path.
    """
    delta_path = shutil.which("delta")
    if delta_path:
        return delta_path
    else:
        return None


def find_rsync() -> str | None:
    """
    Check if the 'rsync' binary is available in the environment and return its full path.
    """
    rsync_path = shutil.which("rsync")
    if rsync_path:
        return rsync_path
    else:
        return None


def get_hostname() -> str | None:
    """
    Determine the hostname of the system.
    """
    # read the HOSTNAME environment variable
    hostname = os.getenv('HOSTNAME')
    if hostname:
        return hostname
    # read the output of `hostname`
    try:
        result = subprocess.run(['hostname'], capture_output=True, text=True, check=True)
        if result.stdout:
            return result.stdout.strip()
    except subprocess.CalledProcessError:
        pass
    # read `/etc/hostname`
    try:
        with open('/etc/hostname', 'r') as file:
            hostname = file.read().strip()
            if hostname:
                return hostname
    except FileNotFoundError:
        pass

    return None


def is_cmd_value(value: str) -> bool:
    """
    Return True if the given value is enclosed in `{{ }}`.
    """
    return value.startswith("{{") and value.endswith("}}")


def resolve_cmd_value(value: str) -> str:
    """
    Execute the shell command encoded in the given value and return the result.
    If no command is encoded, return the original value.
    """
    if not is_cmd_value(value):
        return value
    command = value[2:-2].strip()
    result = subprocess.run(command, shell=True, capture_output=True, text=True, check=True)
    return result.stdout.strip()


def validate_groups(groups: dict) -> None:
    """
    Validates the groups by checking the 'files' list. Only the following mappings are allowed:
    - file <-> file
    - directory <-> directory
    """
    for group_name, group in groups.items():
        for src, dst in itertools.chain(group.install_files, group.sync_files):
            src_path = Path(src)
            dst_path = Path(dst)
            # if one does not exist, it will be created
            if src_path.exists() and dst_path.exists():
                if src_path.is_file() and not dst_path.is_file():
                    raise ConfitError(f"Invalid mapping in group '{group_name}': '{src}' is a file, while '{dst}' is not.")
                if src_path.is_dir() and not dst_path.is_dir():
                    raise ConfitError(f"Invalid mapping in group '{group_name}': '{src}' is a directory, while '{dst}' is not.")


def load_config() -> tuple[dict, dict[str, ConfGroup]]:
    """
    Load settings and configuration groups from the config file.
    Returns the raw dict and the ConfGroups instances.
    """
    for cf in confit_files:
        confit_file = Path(cf)
        if confit_file.exists():
            with open(confit_file, 'r') as file:
                try:
                    data = yaml.safe_load(file)
                except Exception as e:
                    raise ConfitError(f"Failed to read '{confit_file}': {e}")
                groups = {}
                current_hostname = get_hostname()
                for key, value in data['groups'].items():
                    # Check if the 'host' key is present and matches the current hostname
                    if 'host' in value and value['host'] != current_hostname:
                        continue
                    try:
                        # 'sync_files' can have 3 values with different effects:
                        # - omited : use 'install_files' as 'sync_files'
                        # - empty list: synchronize nothing
                        # - list of tuples: synchronize file/drectory pairs in the list
                        sync_files = None
                        if 'sync_files' in value:
                            if len(value['sync_files']) > 0:
                                sync_files = [(src, dst) for src, dst in value['sync_files']]
                            else:
                                sync_files = []
                        # create the ConfGroup
                        groups[key] = ConfGroup(
                            name=key,
                            # destination can be a command value
                            dest=Path(resolve_cmd_value(value['dest'])),
                            install_files=[(src, dst) for src, dst in value['install_files']],
                            sync_files=sync_files,
                            post_install_cmds=[(cmd, wdir) for cmd, wdir in value.get('post_install_cmds', [])],
                            check_binaries=[(_bin, desc) for _bin, desc in value.get('check_binaries', [])],
                            max_backups=value.get('max_backups', 5)
                        )
                    except KeyError as e:
                        raise ConfitError(f"The following key is missing in ConfGroup '{key}': {e}")
                    except ValueError as e:
                        raise ConfitError(f"Wrong format detected in ConfGroup '{key}': {e}")
                validate_groups(groups)
                return (data, groups)
    raise ConfitError("Could not find a valid 'conf.it' file.")


def init_globals() -> None:
    """
    Initialize the global variables containing the configuration data and ConfGroups.
    """
    global config, groups, delta, rsync
    # don't load the config file multiple times
    if 'config' not in globals() or 'groups' not in globals():
        config, groups = load_config()
        delta = find_delta()
        rsync = find_rsync()


def backup_cmd(args: argparse.Namespace) -> None:
    """ Handle the 'backup' command. """
    for group in groups.values():
        if group.name == args.group or args.group == 'all':
            group.backup()


def diff_cmd(args: argparse.Namespace) -> None:
    """ Handle the 'diff' command. """
    for group in groups.values():
        if group.name == args.group or args.group == 'all':
            group.diff()


def install_cmd(args: argparse.Namespace) -> None:
    """ Handle the 'install' command.  """
    for group in groups.values():
        if group.name == args.group or args.group == 'all':
            if not args.no_backup:
                group.backup(files='install')
            group.install(force=args.no_backup)
            if not args.no_post_install:
                group.post_install()


def apply_cmd(args: argparse.Namespace) -> None:
    """ Handle the 'apply' command.  """
    for group in groups.values():
        if group.name == args.group or args.group == 'all':
            if not args.no_backup:
                group.backup(files='sync')
            group.apply(force=args.no_backup)


def post_install_cmd(args: argparse.Namespace) -> None:
    """ Handle the 'post_install' command.  """
    for group in groups.values():
        if group.name == args.group or args.group == 'all':
            group.post_install()


def sync_cmd(args: argparse.Namespace) -> None:
    """ Handle the 'sync' command.  """
    for group in groups.values():
        if group.name == args.group or args.group == 'all':
            group.synchronize()


def check_cmd(args: argparse.Namespace) -> None:
    """ Handle the 'check' command.  """
    for group in groups.values():
        if group.name == args.group or args.group == 'all':
            group.check()


def groups_cmd(args: argparse.Namespace) -> None:
    """ Handle the 'groups' command.  """
    if args.group:
        # If a groups has been specified, print the YAML data
        # from the config file
        group = groups.get(args.group)
        if group:
            group_data = config['groups'].get(args.group)
            if group_data:
                printq(yaml.dump({args.group: group_data}, default_flow_style=False))
            else:
                printq(f"Group '{args.group}' not found in the confit file.")
        else:
            printq(f"Group '{args.group}' not found.")
    else:
        for group_name in groups.keys():
            printq(group_name)


def update_self_cmd(args: argparse.Namespace) -> None:
    """
    Updates the `confit` file using the `pygit2` module.
    """
    try:
        import pygit2  # type: ignore[import]
        import requests
    except ImportError as e:
        printq(f"The 'update' command requires 'pygit2' and 'requests': {e}")
        sys.exit(1)

    update_files = [
        ('https://raw.githubusercontent.com/juk0de/confit/master/confit', 'confit'),
        ]

    # makes sure the repository is NOT dirty
    try:
        repo = pygit2.Repository('.')
        status = repo.status()
        if status:
            printe("The repository is dirty. Please commit or stash your changes before updating.")
            sys.exit(1)
    except pygit2.GitError as e:
        printe(f"Failed to access the repository: {e}")
        sys.exit(1)

    printq("=> Updating")
    # download the update files
    for url, local_path in update_files:
        try:
            response = requests.get(url)
            response.raise_for_status()
            with open(local_path, 'wb') as file:
                file.write(response.content)
            printq(f"> Updated '{local_path}' from '{url}'.")
        except requests.RequestException as e:
            printe(f"> Failed to download latest version of '{local_path}': {e}")
            sys.exit(1)

    # commit the changes if there are any
    try:
        index = repo.index
        index.add_all()
        index.write()
        if repo.status():
            if args.no_commit:
                printq("> Files have been updated. Make sure to commit the  changes.")
            else:
                author = pygit2.Signature('confit update', 'https://github.com/juk0de/confit/')
                committer = pygit2.Signature('confit update', 'https://github.com/juk0de/confit/')
                tree = index.write_tree()
                repo.create_commit(
                    'refs/heads/master',  # the name of the reference to update
                    author,  # the author of the commit
                    committer,  # the committer of the commit
                    'update from upstream',  # the commit message
                    tree,  # the tree object this commit points to
                    [repo.head.target]  # the parents of the new commit
                )
                printq("> Committed the changes with message 'update from upstream'")
        else:
            printq("> No changes detected, nothing to commit.")
    except pygit2.GitError as e:
        printe(f"> Failed to commit the changes: {e}")
        sys.exit(1)
    printq("> UPDATE SUCCESSFUL!")


class GroupChoicesAction(argparse.Action):
    def __call__(self, parser, namespace, values, option_string=None):
        global config, groups
        try:
            init_globals()
        except ConfitError as e:
            parser.error(str(e))
        if values == "all":
            setattr(namespace, self.dest, values)
        else:
            if values not in groups:
                parser.error(f"Invalid choice: '{values}' (choose from {list(groups.keys()) + ['all']})")
            setattr(namespace, self.dest, values)


def main() -> None:
    # Ensure the script is called from its residing directory
    script_dir = Path(__file__).resolve().parent
    current_dir = Path.cwd().resolve()
    if script_dir != current_dir:
        printe(f"Error: 'confit' must be run from: {script_dir}")
        sys.exit(1)
    # main parser
    parser = argparse.ArgumentParser(description="confit: manage config files and tools, organized by groups")
    parser.add_argument('--quiet', '-q',
                        action='store_true',
                        help="Disable all output")
    # subcommand parsers
    subparsers = parser.add_subparsers(dest="command", required=True, help="Subcommands")
    # command 'install'
    install_parser = subparsers.add_parser("install",
                                           aliases=['i'],
                                           help="Install the given group to its destination")
    install_parser.add_argument("group", action=GroupChoicesAction, help="Group name")
    install_parser.add_argument("--no-backup", "-B", action='store_true',
                                help="Do not backup files before installation (overwrite them instead)")
    install_parser.add_argument("--no-post-install", "-P", action='store_true',
                                help="Do not run post-install commands")
    install_parser.set_defaults(func=install_cmd)
    # command 'apply'
    apply_parser = subparsers.add_parser("apply",
                                         aliases=['a'],
                                         help="Copy the 'sync_files' of the given group to their destination")
    apply_parser.add_argument("group", action=GroupChoicesAction, help="Group name")
    apply_parser.add_argument("--no-backup", "-B", action='store_true',
                              help="Do not backup files (overwrite them instead)")
    apply_parser.set_defaults(func=apply_cmd)
    # command 'backup'
    backup_parser = subparsers.add_parser("backup",
                                          aliases=['b'],
                                          help="Back up the given group (by renaming the destinations files and folders)")
    backup_parser.add_argument("group", action=GroupChoicesAction, help="Group name")
    backup_parser.set_defaults(func=backup_cmd)
    # command 'post-install'
    post_install_parser = subparsers.add_parser("post-install",
                                                aliases=['pi'],
                                                help="Run the 'post_install_cmds' of the given group")
    post_install_parser.add_argument("group", action=GroupChoicesAction, help="Group name")
    post_install_parser.set_defaults(func=post_install_cmd)
    # command 'diff'
    diff_parser = subparsers.add_parser("diff",
                                        aliases=['d'],
                                        help="Print unified diff between repo and destination files of the given group")
    diff_parser.add_argument("group", action=GroupChoicesAction, help="Group name")
    diff_parser.set_defaults(func=diff_cmd)
    # command 'sync'
    sync_parser = subparsers.add_parser("sync",
                                        aliases=['s'],
                                        help="Copy the 'sync_files' of the given group from their destination to this repo")
    sync_parser.add_argument("group", action=GroupChoicesAction, help="Group name")
    sync_parser.set_defaults(func=sync_cmd)
    # command 'check'
    check_parser = subparsers.add_parser("check",
                                         aliases=['c'],
                                         help="Check for availability of the 'check_binaries' of the given group")
    check_parser.add_argument("group", action=GroupChoicesAction, help="Group name")
    check_parser.set_defaults(func=check_cmd)
    # command 'groups'
    groups_parser = subparsers.add_parser("groups",
                                          aliases=['g'],
                                          help="List all known groups or show details about the given one")
    groups_parser.add_argument("group", nargs='?', help="Group name (for details)")
    groups_parser.set_defaults(func=groups_cmd)
    # command 'update-self'
    update_self_parser = subparsers.add_parser("update-self",
                                               aliases=['us'],
                                               help="Update the confit binary from upstream (and commit them to this repo)")
    update_self_parser.add_argument("--no-commit", "-n", action='store_true',
                                    help="Skip automated commit after update")
    update_self_parser.set_defaults(func=update_self_cmd)

    args = parser.parse_args()
    global quiet
    quiet = args.quiet
    # do not read the configuration file for the 'update-self' function
    if args.func != update_self_cmd:
        try:
            init_globals()
        except ConfitError as e:
            printe(e)
            sys.exit(1)

    args.func(args)


if __name__ == "__main__":
    main()
